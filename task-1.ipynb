{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:00.351293Z",
     "iopub.status.busy": "2025-01-29T02:25:00.350892Z",
     "iopub.status.idle": "2025-01-29T02:25:31.045453Z",
     "shell.execute_reply": "2025-01-29T02:25:31.044792Z",
     "shell.execute_reply.started": "2025-01-29T02:25:00.351256Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0-rc1\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.12.14)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=21801845190b7fc2d5d19feb6f8b653cdcefa9de1635e7282070e83539a55b4f\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 5.2.0\n",
      "    Uninstalling chardet-5.2.0:\n",
      "      Successfully uninstalled chardet-5.2.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.7\n",
      "    Uninstalling httpcore-1.0.7:\n",
      "      Successfully uninstalled httpcore-1.0.7\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.28.1\n",
      "    Uninstalling httpx-0.28.1:\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langsmith 0.2.3 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
      "openai 1.57.4 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0-rc1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from datasets import load_dataset, Audio, DatasetDict\n",
    "from collections import Counter\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from googletrans import Translator\n",
    "from IPython.display import clear_output\n",
    "from transformers import TrainerCallback\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tempfile\n",
    "\n",
    "from IPython.display import Audio as IPythonAudio\n",
    "import librosa\n",
    "from transformers import pipeline, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "import traceback\n",
    "from datasets import Dataset as hgdataset\n",
    "\n",
    "from transformers import TFBertModel, TFWav2Vec2Model\n",
    "from transformers import TFDistilBertModel\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text file loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:31.047095Z",
     "iopub.status.busy": "2025-01-29T02:25:31.046519Z",
     "iopub.status.idle": "2025-01-29T02:25:31.583744Z",
     "shell.execute_reply": "2025-01-29T02:25:31.582854Z",
     "shell.execute_reply.started": "2025-01-29T02:25:31.047070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_malayalam = pd.read_excel(\"/kaggle/input/shared-task-hunt/Train set/malayalam/text/ML-AT-train.xlsx\")\n",
    "\n",
    "df_test_malayalam = pd.read_excel(\"/kaggle/input/shared-task-hunt/Test set/malayalam/text/ML-AT-test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio file loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:31.586026Z",
     "iopub.status.busy": "2025-01-29T02:25:31.585453Z",
     "iopub.status.idle": "2025-01-29T02:25:31.610756Z",
     "shell.execute_reply": "2025-01-29T02:25:31.610138Z",
     "shell.execute_reply.started": "2025-01-29T02:25:31.586000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ml_audio_dir = \"/kaggle/input/shared-task-hunt/Train set/malayalam/audio\"\n",
    "ml_audio_test_dir = \"/kaggle/input/shared-task-hunt/Test set/malayalam/audio\"\n",
    "ml_audio_files = [os.path.join(ml_audio_dir, file) for file in os.listdir(ml_audio_dir) if file.endswith(\".wav\")]\n",
    "ml_audio_test_files = [os.path.join(ml_audio_test_dir, file) for file in os.listdir(ml_audio_test_dir) if file.endswith(\".wav\")]\n",
    "ml_file_name = [os.path.join(\"\", file) for file in os.listdir(ml_audio_dir) if file.endswith(\".wav\")]\n",
    "\n",
    "all_audio_files = ml_audio_files\n",
    "all_file_name = ml_file_name\n",
    "all_audio_test_file = ml_audio_test_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:31.612363Z",
     "iopub.status.busy": "2025-01-29T02:25:31.612064Z",
     "iopub.status.idle": "2025-01-29T02:25:31.617054Z",
     "shell.execute_reply": "2025-01-29T02:25:31.616128Z",
     "shell.execute_reply.started": "2025-01-29T02:25:31.612340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The size of the Total dataset (883, 3)\n",
      " The size of the Test dataset (50, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_malayalam.copy()\n",
    "df_test = df_test_malayalam.copy()\n",
    "print(f\" The size of the Total dataset {df_train.shape}\")\n",
    "print(f\" The size of the Test dataset {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:31.617900Z",
     "iopub.status.busy": "2025-01-29T02:25:31.617687Z",
     "iopub.status.idle": "2025-01-29T02:25:31.642857Z",
     "shell.execute_reply": "2025-01-29T02:25:31.642093Z",
     "shell.execute_reply.started": "2025-01-29T02:25:31.617878Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label Short</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>H_ML_001_C_F_044_001</td>\n",
       "      <td>നമസ്കാരം ഒരു ഒരു പരമ ചെറ്റയുടെ കാര്യമാണ് ഞാൻ പ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>H_ML_001_C_F_044_002</td>\n",
       "      <td>ആദ്യം തന്നെ അവൻറെ ഐഡിയുടെ പേര് വരെ ഞാൻ ഇതിനകത്...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>H_ML_001_C_F_044_003</td>\n",
       "      <td>അവൻറെ ആ ചെറ്റയുടെ ആ പരമനാറിയുടെ പേര്</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>H_ML_001_C_F_044_004</td>\n",
       "      <td>അവന്റെ ദുഷിച്ച മനസ്സ് കൊണ്ടുവന്ന് എൻറെ വീഡിയോയ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>H_ML_001_C_F_044_005</td>\n",
       "      <td>നിൻറെ ദുഷിപ്പ് എല്ലാം എന്തിനാ എന്റെ നേർക്ക് തീ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class Label Short             File Name  \\\n",
       "0                 C  H_ML_001_C_F_044_001   \n",
       "1                 C  H_ML_001_C_F_044_002   \n",
       "2                 C  H_ML_001_C_F_044_003   \n",
       "3                 C  H_ML_001_C_F_044_004   \n",
       "4                 C  H_ML_001_C_F_044_005   \n",
       "\n",
       "                                          Transcript  \n",
       "0  നമസ്കാരം ഒരു ഒരു പരമ ചെറ്റയുടെ കാര്യമാണ് ഞാൻ പ...  \n",
       "1  ആദ്യം തന്നെ അവൻറെ ഐഡിയുടെ പേര് വരെ ഞാൻ ഇതിനകത്...  \n",
       "2               അവൻറെ ആ ചെറ്റയുടെ ആ പരമനാറിയുടെ പേര്  \n",
       "3  അവന്റെ ദുഷിച്ച മനസ്സ് കൊണ്ടുവന്ന് എൻറെ വീഡിയോയ...  \n",
       "4  നിൻറെ ദുഷിപ്പ് എല്ലാം എന്തിനാ എന്റെ നേർക്ക് തീ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:31.643897Z",
     "iopub.status.busy": "2025-01-29T02:25:31.643621Z",
     "iopub.status.idle": "2025-01-29T02:25:31.654713Z",
     "shell.execute_reply": "2025-01-29T02:25:31.654035Z",
     "shell.execute_reply.started": "2025-01-29T02:25:31.643869Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ML_TE_31</td>\n",
       "      <td>നമ്മൾ എന്താ സർവാണികളോ അതോ ചില ഇറച്ചി കടിപിടി ക...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ML_TE_008</td>\n",
       "      <td>കേട്ടോടാ മറ്റേ മോനെ നിൻറെ അമ്മയെ ചെന്ന് വിളിക്...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ML_TE_009</td>\n",
       "      <td>ഈ പൂറി മോൻ ഈ പുണ്ടചി തയോളി പറയുകയാണ്</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ML_TE_39</td>\n",
       "      <td>മുസ്ലീങ്ങളെ പീഡിപ്പിക്കപ്പെടുന്നില്ല എന്നാണെങ്...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ML_TE_38</td>\n",
       "      <td>പശുവിനെ മാംസം തിന്നോളണമെന്നില്ല അടുത്തുകൂടെ പോ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    File Name                                         Transcript\n",
       "48   ML_TE_31  നമ്മൾ എന്താ സർവാണികളോ അതോ ചില ഇറച്ചി കടിപിടി ക...\n",
       "35  ML_TE_008  കേട്ടോടാ മറ്റേ മോനെ നിൻറെ അമ്മയെ ചെന്ന് വിളിക്...\n",
       "36  ML_TE_009               ഈ പൂറി മോൻ ഈ പുണ്ടചി തയോളി പറയുകയാണ്\n",
       "31   ML_TE_39  മുസ്ലീങ്ങളെ പീഡിപ്പിക്കപ്പെടുന്നില്ല എന്നാണെങ്...\n",
       "30   ML_TE_38  പശുവിനെ മാംസം തിന്നോളണമെന്നില്ല അടുത്തുകൂടെ പോ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:31.655742Z",
     "iopub.status.busy": "2025-01-29T02:25:31.655432Z",
     "iopub.status.idle": "2025-01-29T02:25:31.666335Z",
     "shell.execute_reply": "2025-01-29T02:25:31.665564Z",
     "shell.execute_reply.started": "2025-01-29T02:25:31.655712Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/shared-task-hunt/Train set/malayalam/audio/H_ML_001_P_M_019_043.wav\n",
      "H_ML_001_P_M_019_043.wav\n",
      "/kaggle/input/shared-task-hunt/Test set/malayalam/audio/ML_TE_40.wav\n"
     ]
    }
   ],
   "source": [
    "print(all_audio_files[0])\n",
    "print(all_file_name[0])\n",
    "print(all_audio_test_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:31.669159Z",
     "iopub.status.busy": "2025-01-29T02:25:31.668964Z",
     "iopub.status.idle": "2025-01-29T02:25:31.680567Z",
     "shell.execute_reply": "2025-01-29T02:25:31.679682Z",
     "shell.execute_reply.started": "2025-01-29T02:25:31.669140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_ML_001_C_F_044_001\n",
      "H_ML_001_P_M_019_043\n"
     ]
    }
   ],
   "source": [
    "text_file_name = list(df_train['File Name'])\n",
    "only_file_name = [file.split('/')[7][:-4] for file in all_audio_files]\n",
    "\n",
    "print(text_file_name[0])\n",
    "print(only_file_name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing files in audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:31.682289Z",
     "iopub.status.busy": "2025-01-29T02:25:31.682090Z",
     "iopub.status.idle": "2025-01-29T02:25:31.712441Z",
     "shell.execute_reply": "2025-01-29T02:25:31.711559Z",
     "shell.execute_reply.started": "2025-01-29T02:25:31.682272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for text, audio in zip(text_file_name, only_file_name):\n",
    "    if(text not in only_file_name):\n",
    "        print(text)\n",
    "\n",
    "for text, audio in zip(text_file_name, only_file_name):\n",
    "    if(audio not in text_file_name):\n",
    "        print(audio)\n",
    "\n",
    "for text in text_file_name:\n",
    "    if(text not in only_file_name):\n",
    "        df_train.drop(df_train[df_train['File Name'] == text].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using back translation for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:31.713672Z",
     "iopub.status.busy": "2025-01-29T02:25:31.713319Z",
     "iopub.status.idle": "2025-01-29T02:25:33.633951Z",
     "shell.execute_reply": "2025-01-29T02:25:33.633265Z",
     "shell.execute_reply.started": "2025-01-29T02:25:31.713637Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 of P 406\n"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n",
    "def back_translate(text, src_lang, intermediate_lang=\"en\"):\n",
    "    try:\n",
    "        translated = translator.translate(text, src=src_lang, dest=intermediate_lang).text\n",
    "        back_translated = translator.translate(translated, src=intermediate_lang, dest=src_lang).text\n",
    "        return back_translated\n",
    "    except Exception as e:\n",
    "        print(f\"Error in back translation: {e}\")\n",
    "        return text\n",
    "\n",
    "classlist = ['C', 'G', 'R', 'P']\n",
    "\n",
    "target = df_train['Class Label Short'].value_counts()['N']\n",
    "augmented_texts = []\n",
    "\n",
    "for x in classlist:\n",
    "    count = df_train['Class Label Short'].value_counts()[x]\n",
    "    tmp = target - count\n",
    "    start = 0\n",
    "    if(x == 'N'):\n",
    "        continue\n",
    "    while(count != target):\n",
    "        for index, row in df_train[df_train['Class Label Short'] == x].iterrows():\n",
    "            original_text = row[\"Transcript\"]\n",
    "            language = row['File Name'].split('_')[1].lower()\n",
    "            \n",
    "            back_translated = back_translate(original_text, src_lang=language)\n",
    "\n",
    "            augmented_texts.append({\"Class Label Short\": row['Class Label Short'], \n",
    "                                    \"File Name\": row['File Name'],\n",
    "                                    \"Transcript\": back_translated})\n",
    "            count = count + 1\n",
    "            start = start + 1\n",
    "            print(f\"{round(start/tmp*100, 2)} of {x} {count}\")\n",
    "            clear_output(wait=True)\n",
    "            if(count == target):\n",
    "                break\n",
    "\n",
    "\n",
    "augmented_df = pd.DataFrame(augmented_texts)\n",
    "df_train = pd.concat([df_train, augmented_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:33.635044Z",
     "iopub.status.busy": "2025-01-29T02:25:33.634822Z",
     "iopub.status.idle": "2025-01-29T02:25:33.640690Z",
     "shell.execute_reply": "2025-01-29T02:25:33.639872Z",
     "shell.execute_reply.started": "2025-01-29T02:25:33.635025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape of train data after augmentation: (2030, 3)\n",
      "Balanaced classes!\n",
      "Class Label Short\n",
      "C    406\n",
      "G    406\n",
      "P    406\n",
      "R    406\n",
      "N    406\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"The new shape of train data after augmentation: {df_train.shape}\")\n",
    "print(\"Balanaced classes!\")\n",
    "print(df_train['Class Label Short'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:33.641859Z",
     "iopub.status.busy": "2025-01-29T02:25:33.641576Z",
     "iopub.status.idle": "2025-01-29T02:25:33.816060Z",
     "shell.execute_reply": "2025-01-29T02:25:33.815311Z",
     "shell.execute_reply.started": "2025-01-29T02:25:33.641830Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the audio file names after augmentation...\n",
      "Number of audios after augmentation: 2030\n",
      "Sample of audio file names: /kaggle/input/shared-task-hunt/Train set/malayalam/audio/H_ML_001_C_F_044_001.wav\n"
     ]
    }
   ],
   "source": [
    "all_audio_files = []\n",
    "\n",
    "for row in df_train.iterrows():\n",
    "    \n",
    "    lang = 'malayalam'\n",
    "    file_name = row[1][1]\n",
    "    \n",
    "    directory = '/kaggle/input/shared-task-hunt/Train set/' + lang + '/audio/' + file_name + '.wav'\n",
    "    all_audio_files.append(directory)\n",
    "\n",
    "print(\"Getting the audio file names after augmentation...\")\n",
    "print(f\"Number of audios after augmentation: {len(all_audio_files)}\")\n",
    "print(f\"Sample of audio file names: {all_audio_files[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:33.816954Z",
     "iopub.status.busy": "2025-01-29T02:25:33.816748Z",
     "iopub.status.idle": "2025-01-29T02:25:33.823423Z",
     "shell.execute_reply": "2025-01-29T02:25:33.822028Z",
     "shell.execute_reply.started": "2025-01-29T02:25:33.816936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0, 'G': 1, 'N': 2, 'P': 3, 'R': 4}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df_train['Class Label Short'] = le.fit_transform(df_train['Class Label Short'])\n",
    "label = list(df_train['Class Label Short'])\n",
    "\n",
    "encoding_dict = {class_label: index for index, class_label in enumerate(le.classes_)}\n",
    "print(encoding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:33.824516Z",
     "iopub.status.busy": "2025-01-29T02:25:33.824221Z",
     "iopub.status.idle": "2025-01-29T02:25:33.840760Z",
     "shell.execute_reply": "2025-01-29T02:25:33.839964Z",
     "shell.execute_reply.started": "2025-01-29T02:25:33.824438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train.drop(columns = ['File Name'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:33.841848Z",
     "iopub.status.busy": "2025-01-29T02:25:33.841608Z",
     "iopub.status.idle": "2025-01-29T02:25:46.100288Z",
     "shell.execute_reply": "2025-01-29T02:25:46.099588Z",
     "shell.execute_reply.started": "2025-01-29T02:25:33.841829Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio sample details: \n",
      " \n",
      " {'audio': '/kaggle/input/shared-task-hunt/Train set/malayalam/audio/H_ML_001_C_F_044_002.wav', 'label': 0}\n",
      "Training set sample {'audio': {'path': '/kaggle/input/shared-task-hunt/Train set/malayalam/audio/H_ML_001_C_F_044_004.wav', 'array': array([ 1.38400713e-09,  1.43312384e-09,  5.80131054e-10, ...,\n",
      "        1.39490863e-09, -1.41438328e-09, -1.33800206e-08]), 'sampling_rate': 16000}, 'label': 0}\n",
      " \n",
      "\n",
      "Test set sample {'audio': {'path': '/kaggle/input/shared-task-hunt/Test set/malayalam/audio/ML_TE_26.wav', 'array': array([-4.95334745e-11,  3.78683612e-11, -4.21996951e-11, ...,\n",
      "        3.24364190e-12,  1.36967816e-11,  2.40900095e-12]), 'sampling_rate': 16000}}\n"
     ]
    }
   ],
   "source": [
    "data_dict = {\"audio\": all_audio_files, \"label\": label}\n",
    "dataset = hgdataset.from_dict(data_dict)\n",
    "dataset\n",
    "\n",
    "\n",
    "data_dict = {\"audio\": all_audio_test_file}\n",
    "test_dataset_audio = hgdataset.from_dict(data_dict)\n",
    "test_dataset_audio\n",
    "\n",
    "audio_sample = dataset[1]\n",
    "print(f\"audio sample details: \\n \\n {audio_sample}\")\n",
    "\n",
    "dataset = dataset.cast_column(\"audio\",\n",
    "     Audio(sampling_rate=16_000))\n",
    "print(f\"Training set sample {dataset[3]}\\n \\n\")\n",
    "\n",
    "test_dataset_audio = test_dataset_audio.cast_column(\"audio\",\n",
    "     Audio(sampling_rate=16_000))\n",
    "print(f\"Test set sample {test_dataset_audio[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:46.101408Z",
     "iopub.status.busy": "2025-01-29T02:25:46.100959Z",
     "iopub.status.idle": "2025-01-29T02:25:46.107591Z",
     "shell.execute_reply": "2025-01-29T02:25:46.106844Z",
     "shell.execute_reply.started": "2025-01-29T02:25:46.101388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def custom_time_stretch(audio, rate=1.2):\n",
    "    \"\"\"Stretch the audio in time.\"\"\"\n",
    "    return librosa.effects.time_stretch(y = audio, rate = rate)\n",
    "\n",
    "def custom_pitch_shift(audio, sampling_rate, n_steps=2):\n",
    "    \"\"\"Shift the pitch of the audio.\"\"\"\n",
    "    return librosa.effects.pitch_shift(y=audio, sr=sampling_rate, n_steps=n_steps)\n",
    "\n",
    "def add_white_noise(audio, noise_factor=0.005):\n",
    "    \"\"\"Add random white noise to the audio.\"\"\"\n",
    "    noise = np.random.randn(len(audio))\n",
    "    return audio + noise_factor * noise\n",
    "\n",
    "def change_volume(audio, factor=1.2):\n",
    "    \"\"\"Change the volume of the audio.\"\"\"\n",
    "    return audio * factor\n",
    "    \n",
    "def augment_audio(audio, sampling_rate):\n",
    "    \"\"\"Apply a series of augmentations to the audio.\"\"\"\n",
    "    # Randomly choose augmentations\n",
    "    aug_choice = random.choice([custom_time_stretch, custom_pitch_shift, add_white_noise, change_volume])\n",
    "    \n",
    "    if aug_choice == custom_time_stretch:\n",
    "        return custom_time_stretch(audio)\n",
    "    elif aug_choice == custom_pitch_shift:\n",
    "        return custom_pitch_shift(audio, sampling_rate)\n",
    "    elif aug_choice == add_white_noise:\n",
    "        return add_white_noise(audio)\n",
    "    elif aug_choice == change_volume:\n",
    "        return change_volume(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:46.108920Z",
     "iopub.status.busy": "2025-01-29T02:25:46.108629Z",
     "iopub.status.idle": "2025-01-29T02:25:48.078623Z",
     "shell.execute_reply": "2025-01-29T02:25:48.077676Z",
     "shell.execute_reply.started": "2025-01-29T02:25:46.108886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f017ff11aded4429b0809291a7837f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f8696553554a11a53b82e654ea121a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa492552e2b9430a8d9980961d3f9327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2651bd62f2be4826a5609a10fe37bbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080c4cc38cd944c388b4ce466e904a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wav2vec2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:25:48.079718Z",
     "iopub.status.busy": "2025-01-29T02:25:48.079430Z",
     "iopub.status.idle": "2025-01-29T02:30:55.300261Z",
     "shell.execute_reply": "2025-01-29T02:30:55.299557Z",
     "shell.execute_reply.started": "2025-01-29T02:25:48.079694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933cca12d822448097e27d02cc09ba4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2030 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 16000\n",
    "\n",
    "def extract_mfcc(audio, sampling_rate=16000, n_mfcc=13, hop_length=512):\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sampling_rate, n_mfcc=n_mfcc, hop_length=hop_length)\n",
    "    return mfcc.T\n",
    "\n",
    "def preprocess_function_wav2vec2(batch, train = True):\n",
    "    audio = batch[\"audio\"][\"array\"]\n",
    "    sampling_rate = batch[\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "    if(train):\n",
    "        label = batch[\"label\"]\n",
    "\n",
    "    if(train):\n",
    "        augmented_audio = augment_audio(audio, sampling_rate)\n",
    "\n",
    "    mfcc_features = extract_mfcc(audio, sampling_rate=sampling_rate)\n",
    "\n",
    "    max_frames = MAX_LENGTH // 512\n",
    "    if mfcc_features.shape[0] > max_frames:\n",
    "        mfcc_features = mfcc_features[:max_frames, :]\n",
    "    else:\n",
    "        mfcc_features = np.pad(mfcc_features, ((0, max_frames - mfcc_features.shape[0]), (0, 0)), \"constant\")\n",
    "\n",
    "\n",
    "    if len(audio) > MAX_LENGTH:\n",
    "        audio = audio[:MAX_LENGTH]\n",
    "    else:\n",
    "        audio = np.pad(audio, (0, MAX_LENGTH - len(audio)), \"constant\")\n",
    "\n",
    "    inputs = wav2vec2_processor(audio, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    batch[\"input_values\"] = inputs[\"input_values\"][0].numpy()\n",
    "    batch[\"mfcc_features\"] = mfcc_features\n",
    "    if(train):\n",
    "        batch[\"labels\"] = label\n",
    "\n",
    "    return batch\n",
    "\n",
    "try:\n",
    "    processed_dataset_wav2vec2 = dataset.map(preprocess_function_wav2vec2)\n",
    "except:\n",
    "    print(\"file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:30:55.301291Z",
     "iopub.status.busy": "2025-01-29T02:30:55.301053Z",
     "iopub.status.idle": "2025-01-29T02:30:55.313606Z",
     "shell.execute_reply": "2025-01-29T02:30:55.312968Z",
     "shell.execute_reply.started": "2025-01-29T02:30:55.301268Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'label', 'input_values', 'mfcc_features', 'labels'],\n",
      "        num_rows: 1624\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['audio', 'label', 'input_values', 'mfcc_features', 'labels'],\n",
      "        num_rows: 406\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_dataset = processed_dataset_wav2vec2.train_test_split(test_size=0.2, seed=42)\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": split_dataset[\"train\"],\n",
    "    \"validation\": split_dataset[\"test\"],\n",
    "})\n",
    "\n",
    "print(split_dataset)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        input_values = torch.tensor(item[\"input_values\"], dtype=torch.float32)\n",
    "        labels = torch.tensor(item[\"labels\"], dtype=torch.long)\n",
    "        return {\"input_values\": input_values, \"labels\": labels}\n",
    "\n",
    "train_dataset = AudioDataset(split_dataset[\"train\"])\n",
    "eval_dataset = AudioDataset(split_dataset[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting unimodals for multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:30:55.314701Z",
     "iopub.status.busy": "2025-01-29T02:30:55.314406Z",
     "iopub.status.idle": "2025-01-29T02:31:08.799789Z",
     "shell.execute_reply": "2025-01-29T02:31:08.799071Z",
     "shell.execute_reply.started": "2025-01-29T02:30:55.314674Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26b09b02f65455a843e9714456f8ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae45d275e550443588ed31fcf044ade4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819753eb209e4220ba8586d065d726b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30967d97b8740ba9906e424ad8c2569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecfca852ec04fd7878799217593dc9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ae97dc3718446bb7e7ebfa254022dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "wav2vec_model = TFWav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback function for f-1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:31:08.800787Z",
     "iopub.status.busy": "2025-01-29T02:31:08.800574Z",
     "iopub.status.idle": "2025-01-29T02:31:08.806645Z",
     "shell.execute_reply": "2025-01-29T02:31:08.805786Z",
     "shell.execute_reply.started": "2025-01-29T02:31:08.800768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MacroF1Callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, validation_data=None):\n",
    "        super(MacroF1Callback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.validation_data = validation_data\n",
    "        self.train_f1_scores = []\n",
    "        self.val_f1_scores = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Calculate F1 score for training data\n",
    "        train_pred = np.argmax(self.model.predict(self.train_data[0]), axis=1)\n",
    "        train_true = self.train_data[1]\n",
    "        train_f1 = f1_score(train_true, train_pred, average='macro')\n",
    "        self.train_f1_scores.append(train_f1)\n",
    "        \n",
    "        # Calculate F1 score for validation data if provided\n",
    "        if self.validation_data is not None:\n",
    "            val_pred = np.argmax(self.model.predict(self.validation_data[0]), axis=1)\n",
    "            val_true = self.validation_data[1]\n",
    "            val_f1 = f1_score(val_true, val_pred, average='macro')\n",
    "            self.val_f1_scores.append(val_f1)\n",
    "            print(f'\\nEpoch {epoch+1}:')\n",
    "            print(f'Training Macro F1-score: {train_f1:.4f}')\n",
    "            print(f'Validation Macro F1-score: {val_f1:.4f}')\n",
    "        else:\n",
    "            print(f'\\nEpoch {epoch+1}:')\n",
    "            print(f'Training Macro F1-score: {train_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting input IDs and mask attention of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:31:08.807755Z",
     "iopub.status.busy": "2025-01-29T02:31:08.807446Z",
     "iopub.status.idle": "2025-01-29T02:31:12.884242Z",
     "shell.execute_reply": "2025-01-29T02:31:12.883329Z",
     "shell.execute_reply.started": "2025-01-29T02:31:08.807734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(texts):\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return tokenized[\"input_ids\"], tokenized[\"attention_mask\"]\n",
    "\n",
    "df_train[\"Transcript\"] = df_train[\"Transcript\"].fillna(\"\").astype(str)\n",
    "text_input_ids, text_attention_mask = preprocess_text(df_train[\"Transcript\"].tolist())\n",
    "text_ids_input = Input(shape=(512,), dtype=tf.int32, name=\"text_ids_input\")\n",
    "text_mask_input = Input(shape=(512,), dtype=tf.int32, name=\"text_mask_attention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting text features from mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:31:12.888002Z",
     "iopub.status.busy": "2025-01-29T02:31:12.887768Z",
     "iopub.status.idle": "2025-01-29T02:31:13.779513Z",
     "shell.execute_reply": "2025-01-29T02:31:13.778527Z",
     "shell.execute_reply.started": "2025-01-29T02:31:12.887983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bert_model_wrapper(inputs):\n",
    "    input_ids, attention_mask = inputs\n",
    "    return bert_model(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "text_features = Lambda(bert_model_wrapper, name=\"bert_embedding\", output_shape=(768,))([text_ids_input, text_mask_input])\n",
    "text_dense = Dense(256, activation=\"relu\", name=\"text_dense\")(text_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:31:13.781036Z",
     "iopub.status.busy": "2025-01-29T02:31:13.780766Z",
     "iopub.status.idle": "2025-01-29T02:31:13.803807Z",
     "shell.execute_reply": "2025-01-29T02:31:13.802918Z",
     "shell.execute_reply.started": "2025-01-29T02:31:13.781014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "audio_input = Input(shape=(16000,), dtype=tf.float32, name=\"audio_input\")\n",
    "mfcc_features_input = Input(shape=(31, 13), dtype=tf.float32, name=\"mfcc_input\")\n",
    "\n",
    "def get_wav2vec_output(x):\n",
    "    return wav2vec_model(x).last_hidden_state\n",
    "\n",
    "wav2vec_output = Lambda(\n",
    "    get_wav2vec_output,\n",
    "    output_shape=(None, 768),\n",
    "    name=\"wav2vec\"\n",
    ")(audio_input)\n",
    "\n",
    "wav2vec_flattened = Lambda(lambda x: x[:, 0, :], name=\"wav2vec_flattened\")(wav2vec_output)\n",
    "mfcc_flattened = Flatten(name=\"mfcc_flattened\")(mfcc_features_input)\n",
    "combined_audio_features = Concatenate(name=\"concat_audio_features\")([wav2vec_flattened, mfcc_flattened])\n",
    "audio_dense = Dense(256, activation=\"relu\", name=\"audio_dense\")(combined_audio_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:31:13.804970Z",
     "iopub.status.busy": "2025-01-29T02:31:13.804716Z",
     "iopub.status.idle": "2025-01-29T02:31:13.811908Z",
     "shell.execute_reply": "2025-01-29T02:31:13.811070Z",
     "shell.execute_reply.started": "2025-01-29T02:31:13.804937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "combined_features = Concatenate(name=\"concat_features\")([audio_dense, text_dense])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:31:13.812914Z",
     "iopub.status.busy": "2025-01-29T02:31:13.812703Z",
     "iopub.status.idle": "2025-01-29T02:31:13.845564Z",
     "shell.execute_reply": "2025-01-29T02:31:13.844656Z",
     "shell.execute_reply.started": "2025-01-29T02:31:13.812895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x = Dense(128, activation=\"relu\", name=\"fc1\")(combined_features)\n",
    "x = Dropout(0.5, name=\"dropout\")(x)\n",
    "output = Dense(5, activation=\"softmax\", name=\"output\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:31:13.852492Z",
     "iopub.status.busy": "2025-01-29T02:31:13.852213Z",
     "iopub.status.idle": "2025-01-29T02:31:13.898629Z",
     "shell.execute_reply": "2025-01-29T02:31:13.897825Z",
     "shell.execute_reply.started": "2025-01-29T02:31:13.852447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ audio_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16000</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ wav2vec (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ audio_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ mfcc_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ wav2vec_flattened         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ wav2vec[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ mfcc_flattened (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">403</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mfcc_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ text_ids_input            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ text_mask_attention       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concat_audio_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1171</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ wav2vec_flattened[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ mfcc_flattened[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bert_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_ids_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                           │                        │                │ text_mask_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ audio_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">300,032</span> │ concat_audio_features… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ text_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ bert_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concat_features           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ audio_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ text_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ audio_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16000\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ wav2vec (\u001b[38;5;33mLambda\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ audio_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ mfcc_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ wav2vec_flattened         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ wav2vec[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)                  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ mfcc_flattened (\u001b[38;5;33mFlatten\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m403\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ mfcc_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ text_ids_input            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ text_mask_attention       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concat_audio_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1171\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ wav2vec_flattened[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ mfcc_flattened[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bert_embedding (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ text_ids_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                           │                        │                │ text_mask_attention[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ audio_dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m300,032\u001b[0m │ concat_audio_features… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ text_dense (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m196,864\u001b[0m │ bert_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concat_features           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ audio_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ text_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ fc1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m65,664\u001b[0m │ concat_features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ fc1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m645\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">563,205</span> (2.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m563,205\u001b[0m (2.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">563,205</span> (2.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m563,205\u001b[0m (2.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multimodal_model = Model(\n",
    "    inputs=[audio_input, mfcc_features_input, text_ids_input, text_mask_input], \n",
    "    outputs=output\n",
    ")\n",
    "\n",
    "multimodal_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "multimodal_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the train & validation data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:31:13.899774Z",
     "iopub.status.busy": "2025-01-29T02:31:13.899446Z",
     "iopub.status.idle": "2025-01-29T02:31:51.499319Z",
     "shell.execute_reply": "2025-01-29T02:31:51.498640Z",
     "shell.execute_reply.started": "2025-01-29T02:31:13.899742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_inputs = {\n",
    "    \"audio_input\": np.stack([x[\"input_values\"] for x in processed_dataset_wav2vec2]),\n",
    "    \"mfcc_input\": np.stack([x[\"mfcc_features\"] for x in processed_dataset_wav2vec2]),\n",
    "    \"text_ids_input\": text_input_ids,\n",
    "    \"text_mask_attention\": text_attention_mask,\n",
    "}\n",
    "\n",
    "train_labels = np.array(label)\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in splitter.split(train_inputs[\"audio_input\"], train_labels):\n",
    "    train_idx = tf.convert_to_tensor(train_idx)\n",
    "    val_idx = tf.convert_to_tensor(val_idx)\n",
    "    train_inputs_final = {\n",
    "        key: tf.gather(value, train_idx) for key, value in train_inputs.items()\n",
    "    }\n",
    "    val_inputs = {\n",
    "        key: tf.gather(value, val_idx) for key, value in train_inputs.items()\n",
    "    }\n",
    "    train_labels_final = tf.gather(train_labels, train_idx)\n",
    "    val_labels = tf.gather(train_labels, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:31:51.500401Z",
     "iopub.status.busy": "2025-01-29T02:31:51.500103Z",
     "iopub.status.idle": "2025-01-29T02:31:51.507391Z",
     "shell.execute_reply": "2025-01-29T02:31:51.506550Z",
     "shell.execute_reply.started": "2025-01-29T02:31:51.500369Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set sizes:\n",
      "audio_input: (1624, 16000)\n",
      "mfcc_input: (1624, 31, 13)\n",
      "text_ids_input: (1624, 512)\n",
      "text_mask_attention: (1624, 512)\n",
      "Training labels: (1624,)\n",
      "\n",
      "Validation set sizes:\n",
      "audio_input: (406, 16000)\n",
      "mfcc_input: (406, 31, 13)\n",
      "text_ids_input: (406, 512)\n",
      "text_mask_attention: (406, 512)\n",
      "Validation labels: (406,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set sizes:\")\n",
    "for key, value in train_inputs_final.items():\n",
    "    print(f\"{key}: {value.shape}\")\n",
    "print(f\"Training labels: {train_labels_final.shape}\")\n",
    "\n",
    "print(\"\\nValidation set sizes:\")\n",
    "for key, value in val_inputs.items():\n",
    "    print(f\"{key}: {value.shape}\")\n",
    "print(f\"Validation labels: {val_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:31:51.508568Z",
     "iopub.status.busy": "2025-01-29T02:31:51.508252Z",
     "iopub.status.idle": "2025-01-29T02:56:10.744994Z",
     "shell.execute_reply": "2025-01-29T02:56:10.744219Z",
     "shell.execute_reply.started": "2025-01-29T02:31:51.508544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 796ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step \n",
      "\n",
      "Epoch 1:\n",
      "Training Macro F1-score: 0.2880\n",
      "Validation Macro F1-score: 0.2809\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 3s/step - accuracy: 0.1952 - loss: 33.3875 - val_accuracy: 0.2833 - val_loss: 9.4685\n",
      "Epoch 2/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 2:\n",
      "Training Macro F1-score: 0.3217\n",
      "Validation Macro F1-score: 0.3225\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.2223 - loss: 25.2513 - val_accuracy: 0.3325 - val_loss: 8.5349\n",
      "Epoch 3/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 3:\n",
      "Training Macro F1-score: 0.3582\n",
      "Validation Macro F1-score: 0.3535\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.2587 - loss: 21.7816 - val_accuracy: 0.3621 - val_loss: 7.4380\n",
      "Epoch 4/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 4:\n",
      "Training Macro F1-score: 0.3844\n",
      "Validation Macro F1-score: 0.3720\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.2737 - loss: 19.0584 - val_accuracy: 0.3768 - val_loss: 6.6545\n",
      "Epoch 5/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 5:\n",
      "Training Macro F1-score: 0.3905\n",
      "Validation Macro F1-score: 0.3825\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3071 - loss: 14.6871 - val_accuracy: 0.3916 - val_loss: 6.0860\n",
      "Epoch 6/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 6:\n",
      "Training Macro F1-score: 0.4207\n",
      "Validation Macro F1-score: 0.4055\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.2970 - loss: 13.8486 - val_accuracy: 0.4138 - val_loss: 5.2824\n",
      "Epoch 7/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 7:\n",
      "Training Macro F1-score: 0.4380\n",
      "Validation Macro F1-score: 0.4121\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3167 - loss: 11.5924 - val_accuracy: 0.4187 - val_loss: 4.6231\n",
      "Epoch 8/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 8:\n",
      "Training Macro F1-score: 0.4806\n",
      "Validation Macro F1-score: 0.4666\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3468 - loss: 10.0301 - val_accuracy: 0.4680 - val_loss: 3.9929\n",
      "Epoch 9/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 9:\n",
      "Training Macro F1-score: 0.5045\n",
      "Validation Macro F1-score: 0.5056\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3542 - loss: 9.1127 - val_accuracy: 0.5074 - val_loss: 3.5986\n",
      "Epoch 10/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 10:\n",
      "Training Macro F1-score: 0.5164\n",
      "Validation Macro F1-score: 0.5012\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3584 - loss: 7.1278 - val_accuracy: 0.5074 - val_loss: 3.2914\n",
      "Epoch 11/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 11:\n",
      "Training Macro F1-score: 0.5448\n",
      "Validation Macro F1-score: 0.5381\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3715 - loss: 6.7428 - val_accuracy: 0.5394 - val_loss: 2.8582\n",
      "Epoch 12/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 12:\n",
      "Training Macro F1-score: 0.5671\n",
      "Validation Macro F1-score: 0.5411\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3919 - loss: 5.4569 - val_accuracy: 0.5419 - val_loss: 2.5579\n",
      "Epoch 13/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 13:\n",
      "Training Macro F1-score: 0.5822\n",
      "Validation Macro F1-score: 0.5541\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3949 - loss: 4.9578 - val_accuracy: 0.5542 - val_loss: 2.3163\n",
      "Epoch 14/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 14:\n",
      "Training Macro F1-score: 0.5974\n",
      "Validation Macro F1-score: 0.5585\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.4285 - loss: 4.3723 - val_accuracy: 0.5591 - val_loss: 2.1054\n",
      "Epoch 15/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 15:\n",
      "Training Macro F1-score: 0.6038\n",
      "Validation Macro F1-score: 0.5645\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.4374 - loss: 3.9462 - val_accuracy: 0.5640 - val_loss: 1.9669\n",
      "Epoch 16/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 16:\n",
      "Training Macro F1-score: 0.6167\n",
      "Validation Macro F1-score: 0.5643\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.4112 - loss: 3.9930 - val_accuracy: 0.5640 - val_loss: 1.8076\n",
      "Epoch 17/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 17:\n",
      "Training Macro F1-score: 0.6232\n",
      "Validation Macro F1-score: 0.5645\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.4419 - loss: 2.9923 - val_accuracy: 0.5690 - val_loss: 1.7021\n",
      "Epoch 18/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 18:\n",
      "Training Macro F1-score: 0.6400\n",
      "Validation Macro F1-score: 0.5767\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.4751 - loss: 2.6772 - val_accuracy: 0.5788 - val_loss: 1.5930\n",
      "Epoch 19/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 19:\n",
      "Training Macro F1-score: 0.6423\n",
      "Validation Macro F1-score: 0.5788\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.4473 - loss: 2.6093 - val_accuracy: 0.5813 - val_loss: 1.5368\n",
      "Epoch 20/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528ms/step\n",
      "\n",
      "Epoch 20:\n",
      "Training Macro F1-score: 0.6625\n",
      "Validation Macro F1-score: 0.5763\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.4670 - loss: 2.4535 - val_accuracy: 0.5813 - val_loss: 1.4529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2e18bd8d00>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_callback = MacroF1Callback(\n",
    "    train_data=(train_inputs_final, train_labels_final),\n",
    "    validation_data=(val_inputs, val_labels)\n",
    ")\n",
    "\n",
    "multimodal_model.fit(\n",
    "    train_inputs_final,\n",
    "    train_labels_final,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(val_inputs, val_labels),\n",
    "    callbacks=[f1_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the test data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:56:10.746119Z",
     "iopub.status.busy": "2025-01-29T02:56:10.745847Z",
     "iopub.status.idle": "2025-01-29T02:56:29.696313Z",
     "shell.execute_reply": "2025-01-29T02:56:29.695621Z",
     "shell.execute_reply.started": "2025-01-29T02:56:10.746097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5fd5c4905044b4bdf8e7ea36192195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step \n"
     ]
    }
   ],
   "source": [
    "test_text_input_ids, test_text_attention_mask = preprocess_text(df_test[\"Transcript\"].tolist())\n",
    "test_processed_dataset_wav2vec2 = test_dataset_audio.map(\n",
    "    preprocess_function_wav2vec2,\n",
    "    fn_kwargs={'train': False}\n",
    ")\n",
    "\n",
    "test_inputs = {\n",
    "    \"audio_input\": np.stack([x[\"input_values\"] for x in test_processed_dataset_wav2vec2]),\n",
    "    \"mfcc_input\": np.stack([x[\"mfcc_features\"] for x in test_processed_dataset_wav2vec2]),\n",
    "    \"text_ids_input\": test_text_input_ids,\n",
    "    \"text_mask_attention\": test_text_attention_mask,\n",
    "}\n",
    "\n",
    "predictions = multimodal_model.predict(test_inputs)\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "prediction_probabilities = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:56:29.697592Z",
     "iopub.status.busy": "2025-01-29T02:56:29.697235Z",
     "iopub.status.idle": "2025-01-29T02:56:29.701623Z",
     "shell.execute_reply": "2025-01-29T02:56:29.700789Z",
     "shell.execute_reply.started": "2025-01-29T02:56:29.697561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    0: 'C',\n",
    "    1: 'G',\n",
    "    2: 'N',\n",
    "    3: 'P',\n",
    "    4: 'R'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:56:29.702605Z",
     "iopub.status.busy": "2025-01-29T02:56:29.702313Z",
     "iopub.status.idle": "2025-01-29T02:56:29.719839Z",
     "shell.execute_reply": "2025-01-29T02:56:29.719156Z",
     "shell.execute_reply.started": "2025-01-29T02:56:29.702583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_letters = [class_mapping[pred] for pred in predicted_classes]\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Predicted_Class': predicted_letters\n",
    "})\n",
    "predictions_df.to_csv('predictions.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6409347,
     "sourceId": 10488249,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
